{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-01T11:24:37.002915Z",
     "iopub.status.busy": "2024-03-01T11:24:37.002535Z",
     "iopub.status.idle": "2024-03-01T11:24:37.014491Z",
     "shell.execute_reply": "2024-03-01T11:24:37.012771Z",
     "shell.execute_reply.started": "2024-03-01T11:24:37.002883Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T11:24:44.399263Z",
     "iopub.status.busy": "2024-03-01T11:24:44.398767Z",
     "iopub.status.idle": "2024-03-01T11:25:14.202139Z",
     "shell.execute_reply": "2024-03-01T11:25:14.200804Z",
     "shell.execute_reply.started": "2024-03-01T11:24:44.399223Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/ac/popularity/code_submission/data/df_github.csv\",index_col = 0 )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T11:25:14.204907Z",
     "iopub.status.busy": "2024-03-01T11:25:14.204495Z",
     "iopub.status.idle": "2024-03-01T11:25:14.212880Z",
     "shell.execute_reply": "2024-03-01T11:25:14.211641Z",
     "shell.execute_reply.started": "2024-03-01T11:25:14.204873Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T20:26:00.262222Z",
     "iopub.status.busy": "2024-02-26T20:26:00.261160Z",
     "iopub.status.idle": "2024-02-26T20:26:00.271298Z",
     "shell.execute_reply": "2024-02-26T20:26:00.269641Z",
     "shell.execute_reply.started": "2024-02-26T20:26:00.262169Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T19:06:38.372225Z",
     "iopub.status.busy": "2024-02-27T19:06:38.371834Z",
     "iopub.status.idle": "2024-02-27T19:06:38.383640Z",
     "shell.execute_reply": "2024-02-27T19:06:38.382585Z",
     "shell.execute_reply.started": "2024-02-27T19:06:38.372198Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"readme\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T19:08:28.409050Z",
     "iopub.status.busy": "2024-02-27T19:08:28.408641Z",
     "iopub.status.idle": "2024-02-27T19:08:32.341183Z",
     "shell.execute_reply": "2024-02-27T19:08:32.340330Z",
     "shell.execute_reply.started": "2024-02-27T19:08:28.409020Z"
    }
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import nltk\n",
    "import pandas\n",
    "\n",
    "include_word_count = False\n",
    "\n",
    "# Regex expressions\n",
    "code_regex = r'`{3}([\\S\\s]*?)`{3}.*'  # Regex to detect code block, same as in prunning.py\n",
    "indent_code_regex = re.compile(r'^((?:(?:[ ]{4}|\\t).*(\\\\R|$))+)',\n",
    "                               re.MULTILINE)  # code from indents https://stackoverflow.com/questions/41351903/how-can-i-match-a-markdown-code-block-with-regex\n",
    "inline_code_regex = r'\\`{1,}([^\\`].*?)\\`{1,}'  # Modified from https://stackoverflow.com/questions/41274241/how-to-capture-inline-markdown-code-but-not-a-markdown-code-fence-with-regex\n",
    "link_regex = r'\\[[^\\]\\r\\n]+\\]\\([^\\)\\r\\n]+\\)'  # Obtained & Modified from https://davidwells.io/snippets/regex-match-markdown-links\n",
    "image_regex = r'!\\[[^\\]\\r\\n]+\\]\\([^\\)\\r\\n]+\\)'  # Modification of the link_regex OLD image: !{1}\\[([^\\[]+)\\](\\(.*\\))\n",
    "lists_regex = re.compile(r'(^ {,3}(-|\\+|\\*|[0-9\\.])+ [\\S\\s]*?\\r\\n\\r\\n)', re.MULTILINE)\n",
    "header_regex = re.compile(r'(#+ )(.+)')  # Group 1 will return all headers\n",
    "\n",
    "links_a_regex = r'(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])'\n",
    "\n",
    "blocks = []\n",
    "final_readme = []\n",
    "indents = []\n",
    "images = []\n",
    "links = []\n",
    "lists = []\n",
    "num_words = []\n",
    "\n",
    "#code_block , header , images , links , code_indent , lists\n",
    "store_code_block = []\n",
    "store_header = []\n",
    "store_images = []\n",
    "store_links = []\n",
    "store_code_indent = []\n",
    "store_lists = []\n",
    "store_a_links = []\n",
    "a_links = []\n",
    "\n",
    "# Types of keys we have in dictionary [content of readmes]\n",
    "keys = ['blocks', 'indents', 'images', 'links', 'lists']  # inlines\n",
    "\n",
    "\n",
    "def get_readme_attributes(readme_file):\n",
    "    num_code_block = len(re.findall(code_regex, readme_file))\n",
    "    \n",
    "    # Now adjusting the readme so that we remove code blocks.\n",
    "    # Links and images are not the same when inside of a code block [We don't want to match them as one]\n",
    "    # Assure headers also don't get mixed with other things\n",
    "    t_code_block = re.findall(code_regex, readme_file)\n",
    "    t_header = re.findall(header_regex, readme_file)\n",
    "    \n",
    "    change = re.sub(code_regex, '', readme_file)\n",
    "    change = re.sub(header_regex, '', change)\n",
    "    \n",
    "    t_code_indent = re.findall(indent_code_regex, change)\n",
    "    num_code_indent = len(t_code_indent)\n",
    "    change = re.sub(indent_code_regex, '', change)\n",
    "\n",
    "    # num_code_inline = len(re.findall(inline_code_regex, change))\n",
    "    # change = re.sub(inline_code_regex, '<inlined code>', change)\n",
    "\n",
    "    num_code_snippets = num_code_block + num_code_indent  # + num_code_inline\n",
    "\n",
    "    # Summarize the rest of the readme file\n",
    "    t_images = re.findall(image_regex, change)\n",
    "    num_images = len(t_images)\n",
    "    change = re.sub(image_regex, '', change)  # Assure links do not capture images\n",
    "    \n",
    "    t_links = re.findall(link_regex, change)\n",
    "    num_links = len(t_links)\n",
    "    change = re.sub(link_regex, '', change)\n",
    "\n",
    "    t_lists = re.findall(lists_regex, change)\n",
    "    num_lists = len(t_lists)\n",
    "    change = re.sub(lists_regex, '', change)\n",
    "\n",
    "    blocks.append(num_code_block)\n",
    "    indents.append(num_code_indent)\n",
    "    images.append(num_images)\n",
    "    links.append(num_links)\n",
    "    lists.append(num_lists)\n",
    "   \n",
    "    store_code_block.append(t_code_block)\n",
    "    store_header.append(t_header)\n",
    "    store_images.append(t_images)\n",
    "    store_links.append(t_links)\n",
    "    store_code_indent.append(t_code_indent)\n",
    "    store_lists.append(t_lists)\n",
    "    \n",
    "    readme_no_lines = change.replace(\"\\n\", \" \").strip()\n",
    "    readme_no_lines = readme_no_lines.replace(\"\\r\", \"\").strip()\n",
    "    readme_no_lines = readme_no_lines.replace(\"\\'\", \"\").strip()\n",
    "    readme_no_lines = re.sub(r'<[^>]*>', '', readme_no_lines)\n",
    "    \n",
    "    t1_links = re.findall(links_a_regex, readme_no_lines)\n",
    "    store_a_links.append(t1_links)\n",
    "    a_num_links = len(t1_links)\n",
    "    a_links.append(a_num_links)\n",
    "    readme_no_lines = re.sub(links_a_regex, '', readme_no_lines)\n",
    "    \n",
    "    final_readme.append(readme_no_lines)\n",
    "\n",
    "    if include_word_count:\n",
    "        tot_words = 0\n",
    "\n",
    "        # Count number of words in dictionary\n",
    "        for word in readme_no_lines.split():\n",
    "            if word in nltk.corpus.words.words():\n",
    "                tot_words += 1\n",
    "\n",
    "        num_words.append(tot_words)\n",
    "\n",
    "for idx,item in df[\"readme\"].items():\n",
    "    get_readme_attributes(item)\n",
    "    \n",
    "\n",
    "df9 = pandas.DataFrame({'processed_readme': final_readme})\n",
    "\n",
    "dataFrames = [ df9]\n",
    "\n",
    "finalResult = pandas.concat(dataFrames, axis=1)\n",
    "\n",
    "print(finalResult.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T19:08:48.483482Z",
     "iopub.status.busy": "2024-02-27T19:08:48.483072Z",
     "iopub.status.idle": "2024-02-27T19:08:48.492105Z",
     "shell.execute_reply": "2024-02-27T19:08:48.491083Z",
     "shell.execute_reply.started": "2024-02-27T19:08:48.483451Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n = pd.concat([df,finalResult],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T19:08:51.182174Z",
     "iopub.status.busy": "2024-02-27T19:08:51.181818Z",
     "iopub.status.idle": "2024-02-27T19:08:51.342107Z",
     "shell.execute_reply": "2024-02-27T19:08:51.341086Z",
     "shell.execute_reply.started": "2024-02-27T19:08:51.182148Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T19:09:32.742726Z",
     "iopub.status.busy": "2024-02-27T19:09:32.742351Z",
     "iopub.status.idle": "2024-02-27T19:09:32.751538Z",
     "shell.execute_reply": "2024-02-27T19:09:32.750328Z",
     "shell.execute_reply.started": "2024-02-27T19:09:32.742700Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n[\"processed_readme\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:55:45.361805Z",
     "iopub.status.busy": "2024-02-28T15:55:45.360696Z",
     "iopub.status.idle": "2024-02-28T15:55:45.365837Z",
     "shell.execute_reply": "2024-02-28T15:55:45.364892Z",
     "shell.execute_reply.started": "2024-02-28T15:55:45.361768Z"
    }
   },
   "outputs": [],
   "source": [
    "#create summary of readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T11:38:40.692342Z",
     "iopub.status.busy": "2024-06-08T11:38:40.691823Z",
     "iopub.status.idle": "2024-06-08T11:38:49.411754Z",
     "shell.execute_reply": "2024-06-08T11:38:49.410416Z",
     "shell.execute_reply.started": "2024-06-08T11:38:40.692305Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained('google-t5/t5-base')\n",
    "model=AutoModelWithLMHead.from_pretrained('google-t5/t5-base', return_dict=True)\n",
    "\n",
    "def get_summary(text):\n",
    "    sequence = (text)\n",
    "    inputs=tokenizer.encode(\"sumarize: \" +sequence,return_tensors='pt', max_length=512, truncation=True)\n",
    "    output = model.generate(inputs, min_length=115, max_length=215)\n",
    "    summary=tokenizer.decode(output[0])\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:56:03.708043Z",
     "iopub.status.busy": "2024-02-28T15:56:03.707341Z",
     "iopub.status.idle": "2024-02-28T15:56:03.712018Z",
     "shell.execute_reply": "2024-02-28T15:56:03.711090Z",
     "shell.execute_reply.started": "2024-02-28T15:56:03.708010Z"
    }
   },
   "outputs": [],
   "source": [
    "summary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:56:05.933370Z",
     "iopub.status.busy": "2024-02-28T15:56:05.932526Z",
     "iopub.status.idle": "2024-02-28T15:56:05.945762Z",
     "shell.execute_reply": "2024-02-28T15:56:05.944940Z",
     "shell.execute_reply.started": "2024-02-28T15:56:05.933333Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T17:04:07.445639Z",
     "iopub.status.busy": "2024-02-28T17:04:07.445270Z",
     "iopub.status.idle": "2024-02-28T18:51:38.802702Z",
     "shell.execute_reply": "2024-02-28T18:51:38.801581Z",
     "shell.execute_reply.started": "2024-02-28T17:04:07.445609Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx,item in df_n[\"processed_readme\"].items():\n",
    "    summary[idx] = get_summary(df_n[\"processed_readme\"][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T19:01:22.998632Z",
     "iopub.status.busy": "2024-02-28T19:01:22.997884Z",
     "iopub.status.idle": "2024-02-28T19:01:23.002695Z",
     "shell.execute_reply": "2024-02-28T19:01:23.001792Z",
     "shell.execute_reply.started": "2024-02-28T19:01:22.998601Z"
    }
   },
   "outputs": [],
   "source": [
    "summary_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T19:01:25.352536Z",
     "iopub.status.busy": "2024-02-28T19:01:25.351780Z",
     "iopub.status.idle": "2024-02-28T19:01:25.359578Z",
     "shell.execute_reply": "2024-02-28T19:01:25.358564Z",
     "shell.execute_reply.started": "2024-02-28T19:01:25.352502Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx,item in df_n[\"processed_readme\"].items():\n",
    "    if summary[idx] == None:\n",
    "        summary_arr.append(None)\n",
    "        continue\n",
    "    summary_arr.append(summary[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T19:01:27.791064Z",
     "iopub.status.busy": "2024-02-28T19:01:27.790353Z",
     "iopub.status.idle": "2024-02-28T19:01:27.796374Z",
     "shell.execute_reply": "2024-02-28T19:01:27.795299Z",
     "shell.execute_reply.started": "2024-02-28T19:01:27.791026Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n[\"summary_t5\"] = summary_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n.to_csv(\"df_github.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T19:01:34.468776Z",
     "iopub.status.busy": "2024-02-28T19:01:34.468033Z",
     "iopub.status.idle": "2024-02-28T19:01:34.472897Z",
     "shell.execute_reply": "2024-02-28T19:01:34.471703Z",
     "shell.execute_reply.started": "2024-02-28T19:01:34.468742Z"
    }
   },
   "outputs": [],
   "source": [
    "#get keywords from description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T19:01:52.943141Z",
     "iopub.status.busy": "2024-02-28T19:01:52.942804Z",
     "iopub.status.idle": "2024-02-28T19:02:07.443542Z",
     "shell.execute_reply": "2024-02-28T19:02:07.442770Z",
     "shell.execute_reply.started": "2024-02-28T19:01:52.943112Z"
    }
   },
   "outputs": [],
   "source": [
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T19:02:07.445393Z",
     "iopub.status.busy": "2024-02-28T19:02:07.444772Z",
     "iopub.status.idle": "2024-02-28T19:02:18.420975Z",
     "shell.execute_reply": "2024-02-28T19:02:18.419875Z",
     "shell.execute_reply.started": "2024-02-28T19:02:07.445359Z"
    }
   },
   "outputs": [],
   "source": [
    "kw_model = KeyBERT()\n",
    "\n",
    "kw_model_multi = KeyBERT('paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T19:02:57.874077Z",
     "iopub.status.busy": "2024-02-28T19:02:57.873146Z",
     "iopub.status.idle": "2024-02-28T19:02:57.878171Z",
     "shell.execute_reply": "2024-02-28T19:02:57.877181Z",
     "shell.execute_reply.started": "2024-02-28T19:02:57.874042Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T19:05:21.966060Z",
     "iopub.status.busy": "2024-02-28T19:05:21.965660Z",
     "iopub.status.idle": "2024-02-28T19:05:54.349929Z",
     "shell.execute_reply": "2024-02-28T19:05:54.348783Z",
     "shell.execute_reply.started": "2024-02-28T19:05:21.966030Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx,item in df_n[\"description\"].items():\n",
    "    keywords[idx] = kw_model.extract_keywords(item, top_n=5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T19:06:25.287563Z",
     "iopub.status.busy": "2024-02-28T19:06:25.287194Z",
     "iopub.status.idle": "2024-02-28T19:06:25.292017Z",
     "shell.execute_reply": "2024-02-28T19:06:25.290995Z",
     "shell.execute_reply.started": "2024-02-28T19:06:25.287532Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T19:07:09.338372Z",
     "iopub.status.busy": "2024-02-28T19:07:09.338001Z",
     "iopub.status.idle": "2024-02-28T19:07:09.346582Z",
     "shell.execute_reply": "2024-02-28T19:07:09.345546Z",
     "shell.execute_reply.started": "2024-02-28T19:07:09.338343Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx,item in df_n[\"processed_readme\"].items():\n",
    "    if keywords[idx] == None:\n",
    "        keywords_arr.append(None)\n",
    "        continue\n",
    "    keywords_arr.append(keywords[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T19:07:10.566031Z",
     "iopub.status.busy": "2024-02-28T19:07:10.565652Z",
     "iopub.status.idle": "2024-02-28T19:07:10.571690Z",
     "shell.execute_reply": "2024-02-28T19:07:10.570759Z",
     "shell.execute_reply.started": "2024-02-28T19:07:10.566003Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n[\"keywords\"] = keywords_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T19:07:42.014154Z",
     "iopub.status.busy": "2024-02-28T19:07:42.013135Z",
     "iopub.status.idle": "2024-02-28T19:07:43.680378Z",
     "shell.execute_reply": "2024-02-28T19:07:43.679574Z",
     "shell.execute_reply.started": "2024-02-28T19:07:42.014115Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n.to_csv(\"df_github.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4510608,
     "sourceId": 7721712,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4510621,
     "sourceId": 7721728,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4518143,
     "sourceId": 7731925,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
